"""
Knowledge Base ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸
ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œë“¤ì„ ì½ì–´ì„œ ì²­í¬ë¡œ ë¶„í• í•˜ê³ , Supabase pgvectorì— ì €ì¥í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    cd web/backend
    python -m scripts.ingest_knowledge
"""
import os
import asyncio
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
sys.path.insert(0, str(Path(__file__).parent.parent))

from supabase import create_client
from dotenv import load_dotenv

# .env íŒŒì¼ ê²½ë¡œ ëª…ì‹œì  ì§€ì • (scripts í´ë”ì˜ ìƒìœ„ = backend í´ë”)
env_path = Path(__file__).parent.parent / ".env"
load_dotenv(dotenv_path=env_path)

# Supabase í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ ì´ë¦„ì€ config.pyì™€ ë™ì¼)
SUPABASE_URL = os.getenv("supabase_url") or os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("supabase_service_key") or os.getenv("SUPABASE_KEY")
OLLAMA_HOST = os.getenv("ollama_host") or os.getenv("OLLAMA_HOST") or "http://localhost:11434"

if not SUPABASE_URL or not SUPABASE_KEY:
    print(f"[DEBUG] env_path: {env_path}")
    print(f"[DEBUG] env_path exists: {env_path.exists()}")
    raise ValueError("supabase_url and supabase_service_key must be set in .env")

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# Knowledge Base ê²½ë¡œ
KNOWLEDGE_BASE_DIR = Path(__file__).parent.parent / "knowledge_base"


async def generate_embedding(text: str) -> list[float]:
    """Ollama nomic-embed-textë¡œ ì„ë² ë”© ìƒì„±"""
    import httpx
    
    async with httpx.AsyncClient(timeout=60.0) as client:
        # ìµœì‹  Ollama API: /api/embed (êµ¬ë²„ì „: /api/embeddings)
        response = await client.post(
            f"{OLLAMA_HOST}/api/embed",
            json={
                "model": "nomic-embed-text",
                "input": text  # ìµœì‹  APIëŠ” 'input' ì‚¬ìš©
            }
        )
        response.raise_for_status()
        result = response.json()
        # ìµœì‹  APIëŠ” 'embeddings' ë°°ì—´ ë°˜í™˜
        embeddings = result.get("embeddings", [])
        return embeddings[0] if embeddings else result.get("embedding", [])


def chunk_markdown(content: str, max_chunk_size: int = 800) -> list[dict]:
    """ë§ˆí¬ë‹¤ìš´ì„ ì„¹ì…˜ ë‹¨ìœ„ë¡œ ì²­í¬ ë¶„í• """
    lines = content.split('\n')
    chunks = []
    current_chunk = []
    current_heading = ""
    
    for line in lines:
        if line.startswith('#'):
            # ì´ì „ ì²­í¬ ì €ì¥
            if current_chunk:
                chunk_text = '\n'.join(current_chunk).strip()
                if chunk_text and len(chunk_text) > 50:  # ë„ˆë¬´ ì§§ì€ ì²­í¬ ì œì™¸
                    chunks.append({
                        "content": chunk_text,
                        "heading": current_heading
                    })
            
            current_heading = line.strip('#').strip()
            current_chunk = [line]
        else:
            current_chunk.append(line)
    
    # ë§ˆì§€ë§‰ ì²­í¬ ì €ì¥
    if current_chunk:
        chunk_text = '\n'.join(current_chunk).strip()
        if chunk_text and len(chunk_text) > 50:
            chunks.append({
                "content": chunk_text,
                "heading": current_heading
            })
    
    return chunks


async def process_document(file_path: Path) -> int:
    """ë‹¨ì¼ ë¬¸ì„œ ì²˜ë¦¬ ë° ì €ì¥"""
    print(f"\nğŸ“„ ì²˜ë¦¬ ì¤‘: {file_path.name}")
    
    content = file_path.read_text(encoding='utf-8')
    chunks = chunk_markdown(content)
    
    print(f"   ì²­í¬ ìˆ˜: {len(chunks)}")
    
    inserted = 0
    for i, chunk in enumerate(chunks):
        print(f"   [{i+1}/{len(chunks)}] ì„ë² ë”© ìƒì„± ì¤‘... ({len(chunk['content'])} chars)")
        
        try:
            embedding = await generate_embedding(chunk['content'])
            
            if not embedding:
                print(f"   âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ (ë¹ˆ ê²°ê³¼)")
                continue
            
            # Supabaseì— ì €ì¥
            result = supabase.table("knowledge_embeddings").insert({
                "content": chunk['content'],
                "metadata": {
                    "source": file_path.name,
                    "heading": chunk['heading'],
                    "chunk_index": i
                },
                "embedding": embedding
            }).execute()
            
            inserted += 1
            print(f"   âœ… ì €ì¥ ì™„ë£Œ: {chunk['heading'][:30]}...")
            
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")
    
    return inserted


async def clear_existing_embeddings():
    """ê¸°ì¡´ ì„ë² ë”© ì‚­ì œ (ì¬ì¸ë±ì‹±ìš©)"""
    print("ğŸ—‘ï¸ ê¸°ì¡´ ì„ë² ë”© ì‚­ì œ ì¤‘...")
    try:
        supabase.table("knowledge_embeddings").delete().neq("id", 0).execute()
        print("   âœ… ì‚­ì œ ì™„ë£Œ")
    except Exception as e:
        print(f"   âš ï¸ ì‚­ì œ ì‹¤íŒ¨ (í…Œì´ë¸”ì´ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ): {e}")


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 50)
    print("ğŸš€ Knowledge Base ì¸ë±ì‹± ì‹œì‘")
    print("=" * 50)
    
    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì˜µì…˜)
    await clear_existing_embeddings()
    
    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ëª©ë¡
    md_files = list(KNOWLEDGE_BASE_DIR.glob("*.md"))
    
    if not md_files:
        print(f"âš ï¸ {KNOWLEDGE_BASE_DIR}ì— ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“š ë°œê²¬ëœ ë¬¸ì„œ: {len(md_files)}ê°œ")
    for f in md_files:
        print(f"   - {f.name}")
    
    # ê° ë¬¸ì„œ ì²˜ë¦¬
    total_inserted = 0
    for file_path in md_files:
        count = await process_document(file_path)
        total_inserted += count
    
    print("\n" + "=" * 50)
    print(f"âœ… ì¸ë±ì‹± ì™„ë£Œ! ì´ {total_inserted}ê°œ ì²­í¬ ì €ì¥ë¨")
    print("=" * 50)


if __name__ == "__main__":
    asyncio.run(main())
